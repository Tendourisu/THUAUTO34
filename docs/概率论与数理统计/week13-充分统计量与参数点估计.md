---
title: week13-充分统计量与参数点估计
tags:
  - 数理统计
categories: 
date: 2025-05-20T19:54:56+08:00
modify: 2025-05-20T19:54:56+08:00
dir: 
share: false
cdate: 2025-05-20T19
mdate: 2025-05-20T19
---

## 一、充分统计量 (Sufficient Statistics)

### 1.1 定义与基本概念 (Definition and Basic Concepts)

- **信息划分**: 样本中包含的关于总体的信息可分为：
    
    1. 关于总体结构的信息（反映总体分布的结构）。
        
    2. 关于总体中未知参数的信息。
        
- **充分统计量的目标**: 提取样本中包含的关于未知参数的**全部**信息，不损失任何信息。
    
- **定义**: 设 X1​,X2​,…,Xn​ 是来自总体 X（分布函数为 F(x,θ)）的简单随机样本。称统计量 T=T(X1​,X2​,…,Xn​) 为参数 θ 的充分统计量，如果在给定 T 的取值后，X1​,X2​,…,Xn​ 的条件分布与 θ 无关。
    
- **说明**:
    
    - 样本 X 所包含的关于 θ 的信息 = T(X) 所包含的关于 θ 的信息 + T(X) 已知后 X 还包含的关于 θ 的信息。
        
    - 若 T(X) 是充分统计量，则后者（T(X) 已知后 X 还包含的信息）为零。
        
- **平凡的充分统计量**: 全样本 T(X)=(X1​,…,Xn​) 自身是一个充分统计量，但实际意义不大。
    

### 1.2 判定充分统计量的方法 (Methods for Determining Sufficient Statistics)

#### 1.2.1 定义法

直接验证在给定统计量 T 的取值 t 后，样本 X1​,…,Xn​ 的条件分布 P(X1​=x1​,…,Xn​=xn​∣T=t) (离散情况) 或条件密度函数 f(x1​,…,xn​∣T=t) (连续情况) 是否与参数 θ 无关。

#### 1.2.2 定理A (Fisher-Neyman Factorization Theorem - Characterization)

若样本 X1​,…,Xn​ 的联合概率密度函数 (pdf) 或联合概率质量函数 (pmf) 为 f(x1​,…,xn​∣θ)，统计量 T=T(X1​,…,Xn​) 的 pdf 或 pmf 为 q(t∣θ)。则 T 为 θ 的充分统计量，当且仅当比值

q(T(x1​,…,xn​)∣θ)f(x1​,…,xn​∣θ)​

与 θ 无关 (当 q(T(x1​,…,xn​)∣θ)>0 时)。

(注：讲义中提到此定理“上课略，有更好的结果”，通常指因子分解定理)

#### 1.2.3 因子分解定理 (Factorization Theorem - Neyman-Fisher)

统计量 T=T(X1​,…,Xn​) 为未知参数 θ 的充分统计量的充要条件是：样本的联合 pdf 或 pmf L(θ;x1​,…,xn​)=f(x1​,…,xn​∣θ) 可以分解为两个非负函数的乘积：

L(θ;x1​,…,xn​)=g(T(x1​,…,xn​),θ)⋅h(x1​,…,xn​)

其中，g(t,θ) 是一个仅通过 $T(x_1, \dots, x_n)$依赖于样本数据并且依赖于 θ 的函数，h(x1​,…,xn​) 是一个仅依赖于样本数据 x1​,…,xn​ 而不依赖于 θ 的函数。

- **证明思路 (离散情况)**:
    
    - 必要性 (⇒): 若 T 是充分的，则 P(X1​=x1​,…,Xn​=xn​∣T=t)=k(x1​,…,xn​) (与 θ 无关)。
        
        P(X1​=x1​,…,Xn​=xn​)=P(X1​=x1​,…,Xn​=xn​∣T=t)P(T=t)=k(x1​,…,xn​)P(T=t)。
        
        令 h(x1​,…,xn​)=k(x1​,…,xn​) 且 g(t,θ)=P(T=t)。
        
    - 充分性 (⇐): 若 P(X1​=x1​,…,Xn​=xn​)=g(t,θ)h(x1​,…,xn​)。
        
        P(T=t)=∑T(x1​,…,xn​)=t​P(X1​=x1​,…,Xn​=xn​)=g(t,θ)∑T(x1​,…,xn​)=t​h(x1​,…,xn​)。
        
        P(X1​=x1​,…,Xn​=xn​∣T=t)=P(T=t)P(X1​=x1​,…,Xn​=xn​)​=g(t,θ)∑T(x1​,…,xn​)=t​h(x1​,…,xn​)g(t,θ)h(x1​,…,xn​)​=∑T(x1​,…,xn​)=t​h(x1​,…,xn​)h(x1​,…,xn​)​，这与 θ 无关。
        

#### 1.2.4 推论

若统计量 T 为 θ 的充分统计量，统计量 S 与 T 存在一一对应关系，则 S 也为 θ 的充分统计量。

### 1.3 例子 (Examples)

#### 例1: 伯努利分布 (Bernoulli Distribution)

设 X1​,…,Xn​ 是来自 B(1,θ) 总体的样本，证明 T=∑i=1n​Xi​ 是 θ 的充分统计量。

- 方法1: 定义法
    
    T=∑Xi​∼B(n,θ), P(T=t)=Cnt​θt(1−θ)n−t.
    
    对于给定的 t=∑xi​:
    
    P(X1​=x1​,…,Xn​=xn​∣T=t)=P(T=t)P(X1​=x1​,…,Xn​=xn​,T=t)​
    
    由于事件 X1​=x1​,…,Xn​=xn​ 蕴含了 T=t (即 ∑xi​=t)，所以
    
    P(X1​=x1​,…,Xn​=xn​,T=t)=P(X1​=x1​,…,Xn​=xn​)=i=1∏n​θxi​(1−θ)1−xi​=θ∑xi​(1−θ)n−∑xi​=θt(1−θ)n−t
    
    因此，
    
    P(X1​=x1​,…,Xn​=xn​∣T=t)=Cnt​θt(1−θ)n−tθt(1−θ)n−t​=Cnt​1​
    
    这与 θ 无关，故 T=∑Xi​ 是充分统计量。
    
- 方法2: 因子分解定理
    
    联合 pmf 为:
    
    L(θ;x1​,…,xn​)=i=1∏n​θxi​(1−θ)1−xi​=θ∑xi​(1−θ)n−∑xi​
    
    令 T(x1​,…,xn​)=∑xi​。
    
    取 g(T(x),θ)=θT(1−θ)n−T 和 h(x1​,…,xn​)=1。
    
    则 L(θ;x)=g(T(x),θ)h(x)。故 T=∑Xi​ 是充分统计量。
    

#### 例2: 正态分布 N(μ,1)  

设 X1​,…,Xn​ 是来自 N(μ,1) 总体的样本，证明 T=Xˉ 是 μ 的充分统计量。

联合 pdf 为:

f(x1​,…,xn​∣μ)=i=1∏n​2π​1​e−2(xi​−μ)2​=(2π​1​)ne−21​∑(xi​−μ)2

我们知道 ∑(xi​−μ)2=∑((xi​−xˉ)+(xˉ−μ))2=∑(xi​−xˉ)2+n(xˉ−μ)2。

所以，

f(x1​,…,xn​∣μ)=(2π​1​)ne−21​(∑(xi​−xˉ)2+n(xˉ−μ)2)

=[(2π​1​)ne−2n(xˉ−μ)2​]⋅[e−21​∑(xi​−xˉ)2]

令 T(x1​,…,xn​)=xˉ。

取 g(T(x),μ)=(2π​1​)ne−2n(xˉ−μ)2​ (实际上，可以吸收部分常数到 h(x)，或更标准的 g(t,θ) 是 T 的密度乘以一个含 θ 的函数)。

更清晰地，可以写成：

g(xˉ,μ)=(2π​1​)ne−2n(xˉ−μ)2​−2nxˉ2​+σ2μnxˉ​−2σ2nμ2​ (这里 σ2=1)

f(x1​,…,xn​∣μ)=e−2n(xˉ−μ)2​⋅(2π​1​)ne−21​∑xi2​+nxˉ2​g(xˉ,μ) part, or part of it⋅e−21​(∑xi2​−nxˉ2)​h(x1​,…,xn​) part, or part of it

A standard factorization is:

f(x1​,…,xn​∣μ)=(2π​1​)ne−2nμ2​+μnxˉ​g(xˉ,μ)⋅e−21​∑xi2​​h(x1​,…,xn​)

这里 T=Xˉ (或 ∑Xi​) 是充分的。

讲义中的证明（使用定理A的思路）：

q(t∣μ) 是 T=Xˉ∼N(μ,1/n) 的密度: q(t∣μ)=2π​n​​e−2n(t−μ)2​.

q(xˉ∣μ)f(x1​,…,xn​∣μ)​=2π​n​​e−2n(xˉ−μ)2​(2π​1​)ne−21​∑(xi​−μ)2​=(2π)−1/2n1/2e−21​(nxˉ2−2nxˉμ+nμ2)(2π)−n/2e−21​(∑xi2​−2μnxˉ+nμ2)​

=(2π)−(n−1)/2n−1/2e−21​(∑xi2​−nxˉ2)=(2π)−(n−1)/2n−1/2e−21​∑(xi​−xˉ)2

这与 μ 无关，故 Xˉ 是充分统计量。

# 例3: 泊松分布 (Poisson Distribution)

设 X1​,X2​ 是来自 P(λ) 总体的样本。

1. 证明 T1​=X1​+X2​ 是 λ 的充分统计量。
    
    X1​∼P(λ),X2​∼P(λ)⇒T1​=X1​+X2​∼P(2λ).
    
    P(T1​=t)=t!e−2λ(2λ)t​.
    
    P(X1​=x1​,X2​=x2​∣T1​=t)=P(T1​=t)P(X1​=x1​,X2​=t−x1​)​ (当 x1​+x2​=t)
    
    =t!e−2λ(2λ)t​x1​!e−λλx1​​⋅(t−x1​)!e−λλt−x1​​​=e−2λ(2λ)t/t!e−2λλt/(x1​!(t−x1​)!)​=x1​!(t−x1​)!t!​(2λ)tλt​=2tCtx1​​​
    
    这与 λ 无关，故 T1​=X1​+X2​ 是充分统计量。
    
2. 证明 T2​=X1​+2X2​ 不是 λ 的充分统计量。
    
    考虑 P(X1​=0,X2​=1∣T2​=2)=P(X1​=0,X2​=1∣X1​+2X2​=2).
    
    这个条件 X1​+2X2​=2 可以由 (X1​=0,X2​=1) 或 (X1​=2,X2​=0) 满足。
    
    P(X1​=0,X2​=1∣T2​=2)=P(X1​+2X2​=2)P(X1​=0,X2​=1 and X1​+2X2​=2)​=P(X1​=0,X2​=1)+P(X1​=2,X2​=0)P(X1​=0,X2​=1)​
    
    =0!e−λλ0​1!e−λλ1​+2!e−λλ2​0!e−λλ0​0!e−λλ0​1!e−λλ1​​=e−2λλ+e−2λλ2/2e−2λλ​=λ+λ2/2λ​=1+λ/21​=2+λ2​
    
    这依赖于 λ，故 T2​=X1​+2X2​ 不是充分统计量。
    

#### 例4: 正态分布 N(μ,σ2) (参数均为未知)

设 X1​,…,Xn​ 是来自 N(μ,σ2) 总体的样本。

联合 pdf 为:

f(x1​,…,xn​∣μ,σ2)=(2π​σ1​)ne−2σ21​∑(xi​−μ)2

=(2π​σ1​)ne−2σ21​(∑xi2​−2μ∑xi​+nμ2)

令 T(x1​,…,xn​)=(∑xi​,∑xi2​)。

取 g(T(x),μ,σ2)=(2π​σ1​)ne−2σ21​(∑xi2​−2μ∑xi​+nμ2) (这里 T(x) 是 (∑xi​,∑xi2​)，所以 g 是 T 和参数的函数) 和 h(x1​,…,xn​)=1。

故 T=(∑Xi​,∑Xi2​) 是 (μ,σ2) 的充分统计量。

等价地，T′=(Xˉ,S2) 也是充分统计量 (其中 S2=n−11​∑(Xi​−Xˉ)2 或 Sn2​=n1​∑(Xi​−Xˉ)2)。

#### 例5: 均匀分布 U(−θ/2,θ/2)  

设 X1​,…,Xn​ 是来自 U(−θ/2,θ/2) 总体的样本。

联合 pdf 为:

f(x1​,…,xn​∣θ)=i=1∏n​θ1​I(−θ/2<xi​<θ/2)

=θn1​I(−θ/2<x(1)​ and x(n)​<θ/2)

其中 x(1)​=min(xi​)，x(n)​=max(xi​)。

令 T(x1​,…,xn​)=(X(1)​,X(n)​).

取 g(T(x),θ)=θn1​I(−θ/2<x(1)​ and x(n)​<θ/2) 和 h(x1​,…,xn​)=1.

故 T=(X(1)​,X(n)​) 是 θ 的充分统计量。

(等价地，θ>max(2X(n)​,−2X(1)​)，所以 T′=max(X(n)​,−X(1)​) 也是充分的)。

### 1.4 关于充分统计量的说明

- **支撑集依赖参数**: 在写联合密度或分布列时，注意支撑集，一般可用示性函数简便表示。
    
- **维度**: 当参数是多维时，充分统计量往往也是多维的，但充分统计量的维数不一定等于参数维数。
    
- **极小充分统计量 (Minimal Sufficient Statistic)**: 是其他任何充分统计量的函数。它以最有效的方式压缩数据而不损失信息。
    

## 二、参数点估计 (Parameter Point Estimation)

### 2.1 基本概念

- **点估计量 (Point Estimator)**: 用于估计未知参数 θ 的样本的函数 θ^=θ^(X1​,…,Xn​)。
    
- **点估计值 (Point Estimate)**: 点估计量在具体样本观测值 x1​,…,xn​ 下的取值 θ^(x1​,…,xn​)。
    

### 2.2 矩估计法 (Method of Moments - MOM)

#### 2.2.1 原理与步骤

- **原理**: 用样本矩估计总体矩。基于大数定律，Mk​=n1​∑i=1n​Xik​P​EXk=μk​。
    
- **步骤**:
    
    1. 求出总体的前 m 阶原点矩（或中心矩，取决于参数形式）： ak​=EXk (或 μk′​=E(X−EX)k)，这些矩通常是未知参数 θ1​,…,θm​ 的函数。
        
    2. 令总体矩等于相应的样本矩：ak​=Mk​=n1​∑i=1n​Xik​ (对 k=1,…,m)。
        
    3. 解由此构成的方程组，得到参数 θ1​,…,θm​ 的估计量 θ^1,MOM,…,θ^m,MOM。
        

#### 2.2.2 例子

##### 例1: X∼B(1,p)  

EX=p。样本一阶矩 M1​=Xˉ。

令 p=Xˉ，则 p^​MOM​=Xˉ。

##### 例2: f(x)=θ36x​(θ−x) for 0<x<θ  

EX=∫0θ​xθ36x​(θ−x)dx=2θ​。

令 EX=Xˉ⇒2θ​=Xˉ⇒θ^MOM​=2Xˉ。

方差: D(θ^MOM​)=D(2Xˉ)=4D(Xˉ)=4nDX​.

EX2=103θ2​, DX=EX2−(EX)2=103θ2​−(2θ​)2=20θ2​.

D(θ^MOM​)=4nθ2/20​=5nθ2​.

##### 例3: f(x)=e−(x−θ) for x≥θ (指数分布平移)

EX=∫θ∞​xe−(x−θ)dx=1+θ.

令 EX=Xˉ⇒1+θ=Xˉ⇒θ^MOM​=Xˉ−1.

### 2.3 极大似然估计法 (Maximum Likelihood Estimation - MLE)

#### 2.3.1 原理与步骤

- **原理 (似然原则)**: 选择使得已观测到的样本数据出现的“可能性”最大的参数值作为估计值。
    
- **似然函数 (Likelihood Function)**:
    
    - 离散总体: L(θ;x1​,…,xn​)=P(X1​=x1​,…,Xn​=xn​;θ)=∏i=1n​P(Xi​=xi​;θ).
        
    - 连续总体: L(θ;x1​,…,xn​)=f(x1​,…,xn​;θ)=∏i=1n​f(xi​;θ).
        
- **步骤**:
    
    1. 写出似然函数 L(θ)。
        
    2. 通常取对数似然函数 lnL(θ) 以简化计算。
        
    3. 求 lnL(θ) (或 L(θ)) 关于参数 θ1​,…,θm​ 的偏导数，并令其为零，构成似然方程组:
        
        ∂θj​∂lnL(θ)​=0,j=1,…,m
    4. 解似然方程组得到 θ^1,MLE,…,θ^m,MLE。
        
    5. **注意**:
        
        - 若似然方程无解，或解不在参数空间内，或解是鞍点/极小值点，则 MLE 可能在参数空间的边界处取到。此时需要直接考察似然函数 L(θ) 在参数定义域内的最大值。
            
        - MLE 可能不唯一。
            

#### 2.3.2 例子

##### 例1: Xi​∼P(λ) (泊松分布)，求 λ 的 MLE。

L(λ;x1​,…,xn​)=∏i=1n​xi​!e−λλxi​​=∏xi​!e−nλλ∑xi​​.

lnL(λ)=−nλ+(∑xi​)lnλ−ln(∏xi​!).

dλdlnL(λ)​=−n+λ∑xi​​=0⇒λ=n∑xi​​=Xˉ.

λ^MLE​=Xˉ.

##### 例2: Xi​∼U[0,θ] (均匀分布)

L(θ;x1​,…,xn​)=∏i=1n​θ1​I(0≤xi​≤θ)=θn1​I(0≤x(1)​ and x(n)​≤θ).

为使 L(θ) 最大，θn 应尽可能小，同时满足 θ≥x(n)​ 和 θ≥0 (因为 xi​≥0)。

所以，θ 的最小允许值为 x(n)​。

θ^MLE=X(n)=max(X1​,…,Xn​).

##### 例3: X∼N(μ,σ2) (正态分布)

lnL(μ,σ2)=−2n​ln(2π)−2n​ln(σ2)−2σ21​∑(xi​−μ)2.

∂μ∂lnL​=σ21​∑(xi​−μ)=0⇒∑xi​−nμ=0⇒μ^​MLE​=Xˉ.

∂σ2∂lnL​=−2σ2n​+2(σ2)2∑(xi​−μ)2​=0.

代入 μ^​MLE​=Xˉ:

−2σ2n​+2(σ2)2∑(xi​−Xˉ)2​=0⇒nσ2=∑(xi​−Xˉ)2⇒σ^MLE2​=n1​∑(Xi​−Xˉ)2=Sn2​.

##### 例4: f(x)=λe−λ(x−μ) for x>μ  

1. λ 已知, 求 μ 的 MLE:
    
    L(μ)=∏λe−λ(xi​−μ)I(xi​>μ)=λne−λ∑(xi​−μ)I(x(1)​>μ).
    
    L(μ)=λne−λ∑xi​enλμI(μ<x(1)​).
    
    为使 L(μ) 最大, enλμ 要最大, 且 μ<x(1)​。故 μ^​MLE=X(1).
    
2. μ 已知, 求 λ 的 MOM:
    
    EX=μ+1/λ.
    
    令 Xˉ=μ+1/λ⇒λ^MOM​=(Xˉ−μ)−1.
    

### 2.4 点估计的评价标准 (Criteria for Evaluating Point Estimators)

#### 2.4.1 无偏性 (Unbiasedness)

- **定义**: 若估计量 θ^ 满足 E(θ^)=θ 对所有 θ∈Θ 成立，则称 θ^ 是 θ 的无偏估计量。
    
- **偏差 (Bias)**: Bias(θ^)=E(θ^)−θ.
    
- **例子**:
    
    - 样本均值 Xˉ 是总体均值 μ 的无偏估计。
        
    - 样本方差 S2=n−11​∑(Xi​−Xˉ)2 是总体方差 σ2 的无偏估计。
        
    - Sn2​=n1​∑(Xi​−Xˉ)2 是 σ2 的有偏估计， E(Sn2​)=nn−1​σ2.
        
    - X∼U[0,θ]: θ^M​=2Xˉ 是无偏的. θ^L=X(n) 是有偏的 (E(X(n)​)=n+1n​θ), 但 nn+1​X(n)​ 是无偏的。
        

#### 2.4.2 有效性 (Efficiency)

- **定义**: 若 θ^1​ 和 θ^2​ 都是 θ 的无偏估计量，如果对任意 θ∈Θ 都有 D(θ^1​)≤D(θ^2​)，且至少对某个 θ0​∈Θ 使得 D(θ^1​)<D(θ^2​) 严格成立，则称 θ^1​ 比 θ^2​ 有效。
    
- 均方误差 (Mean Squared Error - MSE):
    
    MSE(θ^)=E[(θ^−θ)2]=D(θ^)+[Bias(θ^)]2.
    
    若 θ^ 无偏，则 MSE(θ^)=D(θ^)。MSE 越小越好。
    
- 例子: X∼Exp(θ) (pdf f(x;θ)=θ1​e−x/θ), Xˉ 和 nX(1)​ 都是 θ 的无偏估计。
    
    D(Xˉ)=D(X)/n=θ2/n.
    
    D(nX(1)​)=n2D(X(1)​). X(1)​∼Exp(n/θ), D(X(1)​)=(θ/n)2=θ2/n2.
    
    D(nX(1)​)=n2(θ2/n2)=θ2.
    
    当 n>1, D(Xˉ)=θ2/n<θ2=D(nX(1)​), 故 Xˉ 比 nX(1)​ 有效。
    

#### 2.4.3 相合性 (Consistency / Asymptotic Unbiasedness)

- 定义: 若当样本容量 n→∞ 时，估计量序列 θ^n​ 依概率收敛于 θ (即 θ^n​P​θ)，则称 θ^n​ 是 θ 的相合估计量 (或一致估计量)。
    
    ∀ϵ>0,limn→∞​P(∣θ^n​−θ∣<ϵ)=1.
    
- **相合性的判断**:
    
    - **定理A (充分条件)**: 若 limn→∞​E(θ^n​)=θ (渐进无偏) 且 limn→∞​D(θ^n​)=0，则 θ^n​ 是 θ 的相合估计量。
        
    - **定理B (连续映射定理)**: 若 θ^n(1)​,…,θ^n(k)​ 分别是 θ1​,…,θk​ 的相合估计，且 g(⋅) 是连续函数，则 g(θ^n(1)​,…,θ^n(k)​) 是 g(θ1​,…,θk​) 的相合估计。
        
- 例子: X∼U[0,θ], θ^L=X(n).
    
    limn→∞​E(X(n)​)=limn→∞​n+1n​θ=θ.
    
    D(X(n)​)=(n+1)2(n+2)n​θ2. limn→∞​D(X(n)​)=0.
    
    故 X(n)​ 是 θ 的相合估计。
    

#### 2.4.4 渐近正态性 (Asymptotic Normality)

某些估计量在 n 较大时，其分布近似于正态分布。例如，极大似然估计量在一定正则条件下具有渐近正态性。

- 例子: X∼U[0,θ], θ^L=X(n). Yn​=n(θ−X(n)​)。
    
    P(Yn​≤y)=P(n(θ−X(n)​)≤y)=P(X(n)​≥θ−y/n)=1−FX(n)​​(θ−y/n).
    
    FX(n)​​(x)=(x/θ)n for 0≤x≤θ.
    
    P(Yn​≤y)=1−((θ−y/n)/θ)n=1−(1−y/(nθ))n.
    
    当 n→∞, P(Yn​≤y)→1−e−y/θ for y>0.
    
    这表明 Yn​ 的极限分布是参数为 1/θ 的指数分布。